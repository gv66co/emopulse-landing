<!DOCTYPE html>
<html lang="lt">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>NEURO-CORE v10.0 OMNI-NEXUS</title>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=JetBrains+Mono:wght@400&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <style>
        :root {
            --neon-blue: #00f2ff;
            --neon-pink: #ff00ff;
            --stress-red: #ff3333;
            --safe-green: #00ff88;
            --panel-bg: rgba(0, 10, 20, 0.95);
        }

        body, html { 
            margin: 0; padding: 0; width: 100%; height: 100%; 
            background: #000; color: #fff; font-family: 'Orbitron', sans-serif; 
            overflow: hidden; touch-action: none;
        }

        /* --- MOBILE OPTIMIZED LAYOUT --- */
        #main-container {
            display: flex; flex-direction: column; height: 100vh; padding: 10px; box-sizing: border-box;
        }

        .hud-panel {
            background: var(--panel-bg); border: 1px solid rgba(0, 242, 255, 0.2);
            padding: 10px; margin-bottom: 8px; border-radius: 4px;
        }

        /* Centrinis vaizdas - Sumažintas mobiliam */
        #scanner-zone {
            position: relative; width: 100%; max-width: 320px; aspect-ratio: 4/3;
            margin: 0 auto; border: 1px solid var(--neon-blue); overflow: hidden;
        }
        video { width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); opacity: 0.4; }
        #face-canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; transform: scaleX(-1); z-index: 10; }

        .stat-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 8px; }
        .label { font-family: 'JetBrains Mono'; font-size: 0.55rem; color: var(--neon-blue); text-transform: uppercase; }
        .val { font-size: 0.85rem; text-shadow: 0 0 8px var(--neon-blue); }

        /* --- LOADING & ERRORS --- */
        #overlay-msg {
            position: fixed; inset: 0; background: #000; z-index: 2000;
            display: flex; flex-direction: column; align-items: center; justify-content: center; text-align: center; padding: 20px;
        }
        .loader-bar { width: 200px; height: 2px; background: #111; margin-top: 15px; }
        #loader-fill { width: 0%; height: 100%; background: var(--neon-blue); transition: 0.3s; }

        /* --- REPORT --- */
        #report {
            position: fixed; inset: 0; background: rgba(0,0,0,0.98); z-index: 3000;
            display: none; flex-direction: column; padding: 25px; overflow-y: auto;
        }

        canvas#live-chart { background: rgba(0,0,0,0.3); width: 100% !important; height: 60px !important; }
        .btn-action {
            background: none; border: 1px solid var(--neon-blue); color: var(--neon-blue);
            padding: 15px; font-family: 'Orbitron'; cursor: pointer; text-transform: uppercase;
        }
    </style>
</head>
<body>

<div id="overlay-msg">
    <div id="init-text">SYSTEM INITIALIZING...</div>
    <div class="loader-bar"><div id="loader-fill"></div></div>
    <div id="https-warning" style="display:none; color:red; margin-top:10px; font-size:0.7rem;">HTTPS REQUIRED FOR CAMERA</div>
    <button id="start-btn" class="btn-action" style="display:none; margin-top:20px;">AUTHORIZE LINK</button>
</div>

<div id="main-container">
    <div class="hud-panel">
        <div class="stat-grid">
            <div><div class="label">Neural State</div><div id="emo-val" class="val">---</div></div>
            <div><div class="label">Stress Index</div><div id="stress-val" class="val">0.00</div></div>
        </div>
    </div>

    <div id="scanner-zone">
        <video id="video-feed" autoplay muted playsinline></video>
        <canvas id="face-canvas"></canvas>
    </div>

    <div class="hud-panel">
        <div class="stat-grid">
            <div><div class="label">Pulse (Est)</div><div id="bpm-val" class="val">--</div></div>
            <div><div class="label">Respiration</div><div id="breath-val" class="val">--</div></div>
            <div><div class="label">Ocular Sync</div><div id="blink-val" class="val">0</div></div>
            <div><div class="label">Blink Thr.</div><div id="thr-val" class="val">--</div></div>
        </div>
    </div>

    <div class="hud-panel">
        <div class="label">Stress Curve (5sec)</div>
        <canvas id="live-chart" width="300" height="60"></canvas>
    </div>
</div>

<div id="report">
    <h2 style="color:var(--neon-blue); border-bottom:1px solid;">NEURAL DEBRIEF</h2>
    <div id="report-data" style="margin: 20px 0; font-family: 'JetBrains Mono'; font-size: 0.8rem; line-height: 1.6;"></div>
    <button class="btn-action" onclick="location.reload()">RE-INITIALIZE</button>
</div>

<script>
let systemActive = false, analysisData = [], blinkCount = 0;
let earHistory = [], earThreshold = 0.25;
let stressHistory = new Array(50).fill(0);
let breathHistory = [], lastNoseY = 0;
let voicesReady = false;
const ANALYSIS_GOAL = 120;
const MODEL_URL = 'https://raw.githubusercontent.com/vladmandic/face-api/master/model/';

// --- HTTPS CHECK ---
if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
    document.getElementById('https-warning').style.display = 'block';
}

// --- AUDIO FIX ---
const synth = window.speechSynthesis;
function initVoices() {
    const v = synth.getVoices();
    if (v.length > 0) voicesReady = true;
}
window.speechSynthesis.onvoiceschanged = initVoices;

function speak(text) {
    if (!voicesReady) return;
    synth.cancel();
    const utter = new SpeechSynthesisUtterance(text);
    const aiVoice = synth.getVoices().find(v => v.lang.includes('en') && (v.name.includes('Female') || v.name.includes('Zira')));
    if (aiVoice) utter.voice = aiVoice;
    utter.rate = 0.9;
    synth.speak(utter);
}

// --- DYNAMIC GRAPH ---
function drawGraph() {
    const canvas = document.getElementById('live-chart');
    const ctx = canvas.getContext('2d');
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.strokeStyle = '#00f2ff';
    ctx.beginPath();
    const step = canvas.width / stressHistory.length;
    stressHistory.forEach((s, i) => {
        const x = i * step;
        const y = canvas.height - (s * canvas.height);
        i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
    });
    ctx.stroke();
}

// --- MESH DRAWING ---
function drawMesh(ctx, landmarks, stress) {
    const pts = landmarks.positions;
    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
    ctx.lineWidth = 1;
    ctx.strokeStyle = stress > 0.4 ? '#ff3333' : '#00f2ff';
    ctx.beginPath();
    for (let i = 0; i < pts.length; i++) {
        for (let j = i + 1; j < pts.length; j++) {
            const d = Math.hypot(pts[i].x - pts[j].x, pts[i].y - pts[j].y);
            if (d < 30) { ctx.moveTo(pts[i].x, pts[i].y); ctx.lineTo(pts[j].x, pts[j].y); }
        }
    }
    ctx.stroke();
}

// --- CORE LOGIC ---
async function masterInit() {
    // Audio unlock via user interaction
    synth.speak(new SpeechSynthesisUtterance(""));
    document.getElementById('start-btn').style.display = 'none';
    document.getElementById('init-text').textContent = "CONNECTING...";

    try {
        const video = document.getElementById('video-feed');
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: { facingMode: "user", width: 400, height: 300 } 
        });
        video.srcObject = stream;
        
        video.onloadedmetadata = () => {
            const canvas = document.getElementById('face-canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            document.getElementById('overlay-msg').style.display = 'none';
            systemActive = true;
            speak("Neural link active.");
            loop();
        };
    } catch (e) {
        document.getElementById('init-text').textContent = "ERROR: CAMERA DENIED";
        document.getElementById('init-text').style.color = "red";
    }
}

async function loop() {
    if (!systemActive) return;
    const video = document.getElementById('video-feed');
    const canvas = document.getElementById('face-canvas');
    const ctx = canvas.getContext('2d');

    const res = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 160 }))
        .withFaceLandmarks().withFaceExpressions();

    if (res) {
        // 1. Ocular Calibration & Blink
        const left = res.landmarks.getLeftEye();
        const right = res.landmarks.getRightEye();
        const getEAR = (eye) => (Math.hypot(eye[1].x-eye[5].x, eye[1].y-eye[5].y) + Math.hypot(eye[2].x-eye[4].x, eye[2].y-eye[4].y)) / (2 * Math.hypot(eye[0].x-eye[3].x, eye[0].y-eye[3].y));
        const ear = (getEAR(left) + getEAR(right)) / 2;
        
        // Dinaminis slenkstis (pirmos 2 sekunde kalibruojasi)
        if (earHistory.length < 50) {
            earHistory.push(ear);
            earThreshold = (earHistory.reduce((a,b)=>a+b)/earHistory.length) * 0.75;
            document.getElementById('thr-val').textContent = "CALIB...";
        } else {
            document.getElementById('thr-val').textContent = earThreshold.toFixed(2);
            if (ear < earThreshold && !this.isB) { this.isB = true; blinkCount++; }
            else if (ear > earThreshold + 0.02) this.isB = false;
        }

        // 2. Respiration (Nose tip vertical movement)
        const noseY = res.landmarks.getNose()[0].y;
        if (lastNoseY) {
            const diff = noseY - lastNoseY;
            breathHistory.push(diff);
            if(breathHistory.length > 60) breathHistory.shift();
            const breathRate = (breathHistory.filter(d => d > 0.5).length / 60) * 15; // Apytikslis
            document.getElementById('breath-val').textContent = Math.round(12 + breathRate) + " RPM";
        }
        lastNoseY = noseY;

        // 3. Stress & UI
        const ex = res.expressions;
        const stress = (ex.angry + ex.fearful + ex.sad) * 1.5;
        stressHistory.push(stress); stressHistory.shift();
        
        document.getElementById('emo-val').textContent = Object.keys(ex).reduce((a,b)=>ex[a]>ex[b]?a:b).toUpperCase();
        document.getElementById('stress-val').textContent = stress.toFixed(2);
        document.getElementById('bpm-val').textContent = Math.round(70 + (stress * 20));
        document.getElementById('blink-val').textContent = blinkCount;

        drawMesh(ctx, res.landmarks, stress);
        drawGraph();
        
        analysisData.push({ stress, bpm: 70 + (stress * 20) });
        if (analysisData.length >= ANALYSIS_GOAL) finalize();
    }
    setTimeout(loop, 100); // Mažiau CPU apkrovos mobiliems
}

function finalize() {
    systemActive = false;
    const avgStress = analysisData.reduce((a,b)=>a+b.stress,0)/analysisData.length;
    const report = document.getElementById('report');
    const data = document.getElementById('report-data');
    
    data.innerHTML = ""; // Clear existing
    const fragment = document.createDocumentFragment();
    const addLine = (txt) => {
        const p = document.createElement('p');
        p.textContent = txt;
        fragment.appendChild(p);
    };

    addLine(`DOMINANT STATE: ${document.getElementById('emo-val').textContent}`);
    addLine(`AVG STRESS INDEX: ${avgStress.toFixed(2)} (Ref: 0.30)`);
    addLine(`EST. CARDIAC: ${document.getElementById('bpm-val').textContent} BPM`);
    addLine(`RESPIRATION: ${document.getElementById('breath-val').textContent}`);
    addLine(`OCULAR EVENTS: ${blinkCount} blinks`);
    addLine(`VERDICT: ${avgStress > 0.3 ? "Critical Load Detected. System suggests cooling." : "Stable Resonance. Peak performance maintained."}`);
    
    data.appendChild(fragment);
    report.style.display = "flex";
    speak("Diagnostics complete. Comparative data ready.");
}

// --- INIT APP ---
async function startApp() {
    const fill = document.getElementById('loader-fill');
    try {
        fill.style.width = "30%";
        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
        fill.style.width = "60%";
        await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
        fill.style.width = "100%";
        await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
        
        document.getElementById('init-text').textContent = "MODELS LOADED";
        document.getElementById('start-btn').style.display = "block";
        initVoices();
    } catch (e) {
        document.getElementById('init-text').textContent = "LOADING ERROR";
    }
}
startApp();
document.getElementById('start-btn').onclick = masterInit;
</script>
</body>
</html>
