<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NEURO-CORE ELITE v4.0 - CYBER LAB</title>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=Inter:wght@300;600&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <style>
        :root {
            --deep-space: #000510;
            --neon-blue: #00e5ff;
            --neon-pink: #ff00ff;
            --ui-border: rgba(0, 229, 255, 0.3);
            --stress-color: #ff3b3b;
        }

        body, html {
            margin: 0; padding: 0; width: 100%; height: 100%;
            background-color: var(--deep-space); color: #81d4fa;
            font-family: 'Orbitron', sans-serif; overflow: hidden;
            touch-action: none;
        }

        /* Loading Overlay */
        #loader {
            position: fixed; inset: 0; background: var(--deep-space);
            z-index: 2000; display: none; flex-direction: column;
            align-items: center; justify-content: center;
            text-align: center;
        }
        .scanline {
            width: 250px; height: 2px; background: var(--neon-blue);
            box-shadow: 0 0 15px var(--neon-blue);
            animation: loadingMove 1.5s infinite ease-in-out;
        }
        @keyframes loadingMove { 0%, 100% { transform: scaleX(0.1); opacity: 0.2; } 50% { transform: scaleX(1); opacity: 1; } }

        /* HUD Panels */
        .panel {
            position: absolute; background: rgba(0, 10, 30, 0.85);
            backdrop-filter: blur(15px); border: 1px solid var(--ui-border);
            padding: 20px; z-index: 10; width: 220px;
        }
        #panel-l { top: 20px; left: 20px; border-left: 4px solid var(--neon-blue); }
        #panel-r { top: 20px; right: 20px; border-right: 4px solid var(--neon-pink); text-align: right; }

        /* Neon Progress Bar */
        .progress-container { width: 100%; height: 6px; background: rgba(255,255,255,0.05); margin: 15px 0; border-radius: 3px; overflow: hidden; }
        #progress-fill { width: 0%; height: 100%; background: linear-gradient(90deg, var(--neon-blue), var(--neon-pink)); box-shadow: 0 0 15px var(--neon-blue); transition: width 0.3s cubic-bezier(0.4, 0, 0.2, 1); }

        /* Report Modal */
        #final-report {
            position: fixed; top: 50%; left: 50%; transform: translate(-50%, -50%);
            width: 90%; max-width: 450px; background: rgba(0, 15, 40, 0.98);
            border: 1px solid var(--neon-blue); border-radius: 8px; padding: 35px; z-index: 1500;
            display: none; box-shadow: 0 0 60px rgba(0, 229, 255, 0.4);
            animation: modalIn 0.4s ease-out;
        }
        @keyframes modalIn { from { opacity: 0; transform: translate(-50%, -45%); } to { opacity: 1; transform: translate(-50%, -50%); } }

        /* Camera Feed */
        #video-container {
            position: absolute; bottom: 25px; left: 25px;
            width: 200px; height: 150px; border: 1px solid var(--neon-blue);
            background: #000; overflow: hidden; border-radius: 4px;
        }
        video { width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); opacity: 0.35; filter: grayscale(0.5) contrast(1.2); }
        canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; transform: scaleX(-1); }

        /* Buttons & Comms */
        #controls { position: absolute; bottom: 50px; left: 50%; transform: translateX(-50%); z-index: 100; display: flex; gap: 15px; }
        .btn {
            background: rgba(0,0,0,0.6); border: 1px solid var(--neon-blue); color: var(--neon-blue);
            padding: 14px 35px; cursor: pointer; font-family: 'Orbitron'; letter-spacing: 3px;
            transition: 0.3s; font-size: 0.8rem;
        }
        .btn:hover { background: var(--neon-blue); color: #000; box-shadow: 0 0 20px var(--neon-blue); }
        .btn-stop { border-color: var(--stress-color); color: var(--stress-color); }
        .btn-stop:hover { background: var(--stress-color); color: #fff; box-shadow: 0 0 20px var(--stress-color); }

        .stat-val { color: #fff; font-size: 1.2rem; text-shadow: 0 0 8px var(--neon-blue); margin-top: 5px; }
        #ai-comms { position: absolute; bottom: 130px; left: 50%; transform: translateX(-50%); width: 80%; text-align: center; color: var(--neon-blue); font-size: 0.75rem; letter-spacing: 2px; }

        @media (max-width: 600px) {
            .panel { width: calc(50% - 30px); padding: 12px; }
            #video-container { width: 140px; height: 105px; bottom: 15px; left: 15px; }
        }
    </style>
</head>
<body>

<div id="loader">
    <div class="scanline"></div>
    <p style="margin-top:25px; letter-spacing:6px; font-size: 0.8rem;">LOADING NEURAL MODULES</p>
</div>

<div id="hud">
    <div id="panel-l" class="panel">
        <div style="font-size:0.6rem; opacity:0.7; letter-spacing: 1px;">NEURAL STATE</div>
        <div id="emo-val" class="stat-val">AWAITING</div>
        <div class="progress-container"><div id="progress-fill"></div></div>
        <div style="font-size:0.6rem; opacity:0.7; margin-top:10px; letter-spacing: 1px;">STRESS INDEX</div>
        <div id="stress-val" class="stat-val">0.00</div>
    </div>
    
    <div id="panel-r" class="panel">
        <div style="font-size:0.6rem; opacity:0.7; letter-spacing: 1px;">HEART RATE</div>
        <div class="stat-val"><span id="bpm-val">--</span> BPM</div>
        <div style="font-size:0.6rem; opacity:0.7; margin-top:28px; letter-spacing: 1px;">SCAN PROGRESS</div>
        <div id="prog-text" class="stat-val">0%</div>
    </div>
</div>

<div id="final-report">
    <h3 style="color:var(--neon-blue); border-bottom:1px solid var(--ui-border); padding-bottom:15px; margin-top:0; letter-spacing:2px;">NEURAL DIAGNOSTICS</h3>
    <div id="report-content" style="font-family:'Inter'; line-height:1.7; font-size:0.95rem; color: #b2ebf2;"></div>
    <button class="btn" style="width:100%; margin-top:25px;" onclick="location.reload()">RE-INITIALIZE LINK</button>
</div>

<div id="ai-comms">> SYSTEM STANDBY</div>

<div id="controls">
    <button id="start-btn" class="btn" onclick="startLab()">START SCAN</button>
    <button id="stop-trigger" class="btn btn-stop" style="display:none;" onclick="stopSystem()">TERMINATE</button>
</div>

<div id="video-container">
    <video id="video-feed" autoplay muted playsinline></video>
    <canvas id="face-canvas"></canvas>
</div>



<script>
let scene, camera, renderer, core, rings = [];
let systemActive = false;
let analysisData = [];
let stream = null;
let lastAITime = 0;
const ANALYSIS_GOAL = 100; // Number of data points to collect
const MODEL_URL = 'https://raw.githubusercontent.com/vladmandic/face-api/master/model/';

// 1. Initial 3D Background
function init3D() {
    scene = new THREE.Scene();
    camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
    renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
    renderer.setPixelRatio(window.devicePixelRatio > 1 ? 2 : 1);
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.body.appendChild(renderer.domElement);

    const geo = new THREE.IcosahedronGeometry(2.5, 3);
    const mat = new THREE.MeshPhongMaterial({ color: 0x00e5ff, wireframe: true, transparent: true, opacity: 0.3 });
    core = new THREE.Mesh(geo, mat);
    scene.add(core);

    for(let i=0; i<2; i++) {
        const r = new THREE.Mesh(
            new THREE.TorusGeometry(4 + i, 0.015, 16, 100),
            new THREE.MeshBasicMaterial({ color: 0x00e5ff, transparent: true, opacity: 0.15 })
        );
        rings.push(r);
        scene.add(r);
    }

    const light = new THREE.PointLight(0xffffff, 2, 100);
    light.position.set(5,5,5);
    scene.add(light, new THREE.AmbientLight(0x404040, 2));
    camera.position.z = 10;

    function animate(t) {
        requestAnimationFrame(animate);
        if(core) {
            core.rotation.y += 0.003;
            core.rotation.z += 0.001;
            rings.forEach((r, i) => r.rotation.z += 0.001 * (i + 1));
        }
        // AI Cycle check (approx every 250ms for performance)
        if(systemActive && t - lastAITime > 250) {
            processNeuralData();
            lastAITime = t;
        }
        renderer.render(scene, camera);
    }
    animate(0);
}

// 2. Adaptive AI Voice (Soft Female)
function speak(text) {
    const synth = window.speechSynthesis;
    synth.cancel();
    const utter = new SpeechSynthesisUtterance(text);
    const voices = synth.getVoices();
    const femaleVoice = voices.find(v => (v.name.includes('Female') || v.name.includes('Zira') || v.name.includes('Google US English')) && v.lang.includes('en'));
    
    if (femaleVoice) utter.voice = femaleVoice;
    utter.pitch = 1.15; utter.rate = 0.88;
    utter.lang = 'en-US';
    
    synth.speak(utter);
    document.getElementById('ai-comms').textContent = "> " + text.toUpperCase();
}

// 3. Lazy Loading & Camera Init
async function startLab() {
    const loader = document.getElementById('loader');
    loader.style.display = 'flex';
    document.getElementById('start-btn').style.display = 'none';

    try {
        await Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
            faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
        ]);

        stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 } });
        const video = document.getElementById('video-feed');
        video.srcObject = stream;
        
        video.onloadedmetadata = () => {
            const canvas = document.getElementById('face-canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            loader.style.display = 'none';
            document.getElementById('stop-trigger').style.display = 'inline-block';
            systemActive = true;
            speak("Neural interface synchronized. Processing biometric stream.");
        };
    } catch (err) {
        loader.style.display = 'none';
        document.getElementById('start-btn').style.display = 'block';
        alert("CRITICAL ERROR: Failed to access camera or neural models.");
    }
}

// 4. Neural Analysis & Stress Calculation
async function processNeuralData() {
    const video = document.getElementById('video-feed');
    const result = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 224 }))
        .withFaceExpressions();

    if (result) {
        const expressions = result.expressions;
        const top = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
        
        // Stress Index: Weighting negative emotions
        const stress = (expressions.angry * 1.5) + (expressions.fearful * 1.2) + (expressions.sad * 0.8) + (expressions.surprised * 0.5);
        
        // Update UI (textContent for security)
        document.getElementById('emo-val').textContent = top.toUpperCase();
        document.getElementById('stress-val').textContent = stress.toFixed(2);
        document.getElementById('bpm-val').textContent = Math.round(72 + (stress * 15) + (expressions.happy * -5));
        
        // Dynamic Core Color
        const targetColor = top === 'angry' ? 0xff3b3b : (top === 'happy' ? 0x00ff88 : 0x00e5ff);
        core.material.color.lerp(new THREE.Color(targetColor), 0.1);
        
        analysisData.push({ emotion: top, stress: stress });
        
        // Update Progress
        const prog = (analysisData.length / ANALYSIS_GOAL) * 100;
        document.getElementById('progress-fill').style.width = prog + "%";
        document.getElementById('prog-text').textContent = Math.round(prog) + "%";

        if (analysisData.length >= ANALYSIS_GOAL) stopSystem();
    }
}

function stopSystem() {
    if (!systemActive) return;
    systemActive = false;
    if(stream) stream.getTracks().forEach(t => t.stop());
    document.getElementById('stop-trigger').style.display = 'none';
    generateReport();
}

function generateReport() {
    const counts = {};
    let avgStress = 0;
    analysisData.forEach(d => {
        counts[d.emotion] = (counts[d.emotion] || 0) + 1;
        avgStress += d.stress;
    });
    avgStress /= analysisData.length;

    const dominant = Object.keys(counts).reduce((a, b) => counts[a] > counts[b] ? a : b);
    const content = document.getElementById('report-content');
    content.textContent = ""; // Clear for security

    const addLine = (txt, bold = false) => {
        const div = document.createElement('div');
        div.style.marginBottom = "8px";
        if(bold) div.style.fontWeight = "bold";
        div.textContent = txt;
        content.appendChild(div);
    };

    addLine(`PRIMARY NEURAL PATTERN: ${dominant.toUpperCase()}`, true);
    addLine(`AVERAGE STRESS INDEX: ${avgStress.toFixed(2)}`);
    addLine(`TOTAL SAMPLES: ${analysisData.length} clusters`);
    
    const summary = document.createElement('div');
    summary.style.marginTop = "15px";
    summary.style.color = "var(--neon-blue)";
    summary.style.fontStyle = "italic";
    summary.textContent = avgStress > 0.5 
        ? "AI Summary: High neural friction detected. System suggests immediate rest and environment recalibration." 
        : "AI Summary: Neural resonance is optimal. High cognitive efficiency maintained throughout the session.";
    content.appendChild(summary);

    document.getElementById('final-report').style.display = 'block';
    speak("Neural diagnostic complete. Session terminated.");
}

window.addEventListener('resize', () => {
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
    renderer.setSize(window.innerWidth, window.innerHeight);
});

// Initialize on load
init3D();
window.speechSynthesis.getVoices(); // Warm up voices
</script>
</body>
</html>
