<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>NEURO-CORE MOBILE ELITE v4.5</title>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=Inter:wght@300;600&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <style>
        :root {
            --deep-space: #000510;
            --neon-blue: #00e5ff;
            --neon-pink: #ff00ff;
            --ui-border: rgba(0, 229, 255, 0.3);
            --stress-color: #ff3b3b;
        }

        body, html {
            margin: 0; padding: 0; width: 100%; height: 100%;
            background-color: var(--deep-space); color: #81d4fa;
            font-family: 'Orbitron', sans-serif; overflow: hidden;
            touch-action: none;
        }

        #loader {
            position: fixed; inset: 0; background: var(--deep-space);
            z-index: 2000; display: none; flex-direction: column;
            align-items: center; justify-content: center;
        }

        /* HUD Panels - Responsive Layout */
        .panel {
            position: absolute; background: rgba(0, 10, 30, 0.8);
            backdrop-filter: blur(10px); border: 1px solid var(--ui-border);
            padding: 12px; z-index: 10; width: calc(50% - 25px);
            max-width: 180px;
        }
        #panel-l { top: 15px; left: 15px; border-left: 3px solid var(--neon-blue); }
        #panel-r { top: 15px; right: 15px; border-right: 3px solid var(--neon-pink); text-align: right; }

        .progress-container { width: 100%; height: 4px; background: rgba(255,255,255,0.1); margin: 8px 0; border-radius: 2px; overflow: hidden; }
        #progress-fill { width: 0%; height: 100%; background: var(--neon-blue); transition: width 0.3s; }

        #final-report {
            position: fixed; top: 50%; left: 50%; transform: translate(-50%, -50%);
            width: 85%; max-width: 350px; background: rgba(0, 15, 40, 0.95);
            border: 1px solid var(--neon-blue); padding: 25px; z-index: 1500;
            display: none; border-radius: 10px; box-shadow: 0 0 40px rgba(0, 229, 255, 0.3);
        }

        /* Camera Feed Optimized for Mobile */
        #video-container {
            position: absolute; bottom: 110px; left: 50%;
            transform: translateX(-50%);
            width: 160px; height: 160px; border: 2px solid var(--ui-border);
            background: #000; overflow: hidden; border-radius: 50%;
            box-shadow: 0 0 20px rgba(0, 229, 255, 0.2);
        }
        video { width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); opacity: 0.5; }
        #face-canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; transform: scaleX(-1); }

        #controls { position: absolute; bottom: 30px; left: 0; width: 100%; text-align: center; z-index: 100; }
        .btn {
            background: rgba(0, 229, 255, 0.1); border: 1px solid var(--neon-blue); color: var(--neon-blue);
            padding: 16px 40px; cursor: pointer; font-family: 'Orbitron'; letter-spacing: 2px;
            font-size: 0.9rem; border-radius: 30px; text-transform: uppercase;
        }

        .stat-val { color: #fff; font-size: 1rem; text-shadow: 0 0 5px var(--neon-blue); }
        #ai-comms { position: absolute; bottom: 85px; left: 50%; transform: translateX(-50%); width: 90%; text-align: center; color: var(--neon-blue); font-size: 0.65rem; letter-spacing: 1px; }

        /* Animation for scanning line */
        .scanline { width: 150px; height: 2px; background: var(--neon-blue); animation: load 1.5s infinite; }
        @keyframes load { 0%, 100% { opacity: 0.2; } 50% { opacity: 1; } }
    </style>
</head>
<body>

<div id="loader">
    <div class="scanline"></div>
    <p style="margin-top:15px; font-size:0.7rem;">CALIBRATING NEURAL SENSORS</p>
</div>

<div id="hud">
    <div id="panel-l" class="panel">
        <div style="font-size:0.55rem; opacity:0.7;">NEURAL CORE</div>
        <div id="emo-val" class="stat-val">READY</div>
        <div class="progress-container"><div id="progress-fill"></div></div>
        <div style="font-size:0.55rem; opacity:0.7; margin-top:5px;">STRESS</div>
        <div id="stress-val" class="stat-val">0.00</div>
    </div>
    <div id="panel-r" class="panel">
        <div style="font-size:0.55rem; opacity:0.7;">PULSE EST.</div>
        <div class="stat-val"><span id="bpm-val">--</span></div>
        <div style="font-size:0.55rem; opacity:0.7; margin-top:18px;">PROGRESS</div>
        <div id="prog-text" class="stat-val">0%</div>
    </div>
</div>

<div id="final-report">
    <h4 style="color:var(--neon-blue); margin:0 0 15px 0; text-align:center;">SCAN COMPLETE</h4>
    <div id="report-content" style="font-family:'Inter'; font-size:0.85rem; line-height:1.6; color:#b2ebf2;"></div>
    <button class="btn" style="width:100%; margin-top:20px; padding:12px;" onclick="location.reload()">RE-SCAN</button>
</div>

<div id="ai-comms">> SYSTEM STANDBY</div>

<div id="controls">
    <button id="start-btn" class="btn" onclick="startLab()">Start Session</button>
</div>

<div id="video-container">
    <video id="video-feed" autoplay muted playsinline></video>
    <canvas id="face-canvas"></canvas>
</div>

<script>
let scene, camera, renderer, core;
let systemActive = false;
let analysisData = [];
let stream = null;
let lastAITime = 0;
const ANALYSIS_GOAL = 80; 
const MODEL_URL = 'https://raw.githubusercontent.com/vladmandic/face-api/master/model/';

// Colors mapping for mesh
const EMOTION_COLORS = {
    neutral: '#00e5ff',
    happy: '#00ff88',
    sad: '#0066ff',
    angry: '#ff3b3b',
    fearful: '#ff00ff',
    disgusted: '#a8ff00',
    surprised: '#ffff00'
};

function init3D() {
    scene = new THREE.Scene();
    camera = new THREE.PerspectiveCamera(75, window.innerWidth/window.innerHeight, 0.1, 1000);
    renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.body.appendChild(renderer.domElement);

    const geo = new THREE.IcosahedronGeometry(2, 2);
    const mat = new THREE.MeshPhongMaterial({ color: 0x00e5ff, wireframe: true });
    core = new THREE.Mesh(geo, mat);
    scene.add(core);

    const light = new THREE.PointLight(0xffffff, 1.5, 100);
    light.position.set(5,5,5);
    scene.add(light, new THREE.AmbientLight(0x404040));
    camera.position.z = 7;

    function animate(t) {
        requestAnimationFrame(animate);
        if(core) core.rotation.y += 0.005;
        if(systemActive && t - lastAITime > 120) {
            processNeuralData();
            lastAITime = t;
        }
        renderer.render(scene, camera);
    }
    animate(0);
}

function speak(text) {
    const utter = new SpeechSynthesisUtterance(text);
    const voices = speechSynthesis.getVoices();
    utter.voice = voices.find(v => v.lang.includes('en') && (v.name.includes('Female') || v.name.includes('Zira'))) || voices[0];
    utter.pitch = 1.2; utter.rate = 0.9;
    speechSynthesis.speak(utter);
    document.getElementById('ai-comms').textContent = "> " + text.toUpperCase();
}

async function startLab() {
    document.getElementById('loader').style.display = 'flex';
    document.getElementById('start-btn').style.display = 'none';

    try {
        await Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
            faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),
            faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL)
        ]);

        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
        const video = document.getElementById('video-feed');
        video.srcObject = stream;
        
        video.onloadedmetadata = () => {
            const canvas = document.getElementById('face-canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            document.getElementById('loader').style.display = 'none';
            systemActive = true;
            speak("Neural link active.");
        };
    } catch (err) {
        alert("Mobile camera access required.");
        location.reload();
    }
}

async function processNeuralData() {
    const video = document.getElementById('video-feed');
    const canvas = document.getElementById('face-canvas');
    const ctx = canvas.getContext('2d');

    const result = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 160 }))
        .withFaceLandmarks()
        .withFaceExpressions();

    if (result) {
        const top = Object.keys(result.expressions).reduce((a, b) => result.expressions[a] > result.expressions[b] ? a : b);
        const meshColor = EMOTION_COLORS[top] || '#00e5ff';
        
        // --- DRAW COLORFUL NEUROMESH ---
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        const pts = result.landmarks.positions;
        ctx.strokeStyle = meshColor;
        ctx.lineWidth = 1.5;
        ctx.globalAlpha = 0.6;
        ctx.beginPath();
        for (let i = 0; i < pts.length; i += 3) {
            for (let j = i + 1; j < pts.length; j += 12) {
                const d = Math.hypot(pts[i].x - pts[j].x, pts[i].y - pts[j].y);
                if (d < 50) {
                    ctx.moveTo(pts[i].x, pts[i].y);
                    ctx.lineTo(pts[j].x, pts[j].y);
                }
            }
        }
        ctx.stroke();

        // Update HUD
        const stress = (result.expressions.angry * 1.5) + (result.expressions.fearful * 1.2);
        document.getElementById('emo-val').textContent = top.toUpperCase();
        document.getElementById('emo-val').style.color = meshColor;
        document.getElementById('stress-val').textContent = stress.toFixed(2);
        document.getElementById('bpm-val').textContent = Math.round(70 + (stress * 20));
        
        analysisData.push({ emotion: top, stress: stress });
        const prog = (analysisData.length / ANALYSIS_GOAL) * 100;
        document.getElementById('progress-fill').style.width = prog + "%";
        document.getElementById('prog-text').textContent = Math.round(prog) + "%";

        if (analysisData.length >= ANALYSIS_GOAL) stopSystem();
    }
}

function stopSystem() {
    systemActive = false;
    if(stream) stream.getTracks().forEach(t => t.stop());
    
    const counts = {};
    analysisData.forEach(d => counts[d.emotion] = (counts[d.emotion] || 0) + 1);
    const dominant = Object.keys(counts).reduce((a, b) => counts[a] > counts[b] ? a : b);
    
    const report = document.getElementById('report-content');
    report.innerHTML = `
        <b>Dominant State:</b> ${dominant.toUpperCase()}<br>
        <b>Neural Stability:</b> ${analysisData.length >= ANALYSIS_GOAL ? 'Verified' : 'Incomplete'}<br><br>
        <i>Summary: Bio-signals indicate a predominantly ${dominant} state. Neural interface suggests optimal recovery.</i>
    `;
    document.getElementById('final-report').style.display = 'block';
    speak("Analysis complete.");
}

window.addEventListener('resize', () => {
    renderer.setSize(window.innerWidth, window.innerHeight);
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
});

init3D();
</script>
</body>
</html>
