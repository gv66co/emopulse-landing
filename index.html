<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NEURO-CORE ELITE v3.0</title>
    <link href="https://fonts.googleapis.com/css2?family=Syncopate:wght@400;700&family=Space+Mono&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <style>
        :root { --neon: #00f2ff; --bg: #00050a; }
        body, html { margin: 0; padding: 0; background: var(--bg); color: var(--neon); font-family: 'Syncopate', sans-serif; overflow: hidden; height: 100%; }
        
        #hud { position: absolute; inset: 0; z-index: 10; padding: 30px; pointer-events: none; }
        .panel { position: absolute; background: rgba(0, 8, 15, 0.85); backdrop-filter: blur(15px); border: 1px solid rgba(0, 242, 255, 0.2); padding: 20px; pointer-events: auto; }
        #panel-l { top: 30px; left: 30px; border-left: 4px solid var(--neon); width: 260px; }
        #panel-r { top: 30px; right: 30px; border-right: 4px solid var(--neon); text-align: right; width: 260px; }
        
        #scan-trigger { position: absolute; bottom: 50px; left: 50%; transform: translateX(-50%); background: none; border: 2px solid var(--neon); color: var(--neon); padding: 15px 40px; font-family: 'Syncopate'; cursor: pointer; letter-spacing: 5px; z-index: 20; pointer-events: auto; transition: 0.3s; }
        #scan-trigger:hover { background: var(--neon); color: #000; box-shadow: 0 0 30px var(--neon); }
        #scan-trigger:disabled { opacity: 0.3; cursor: wait; }

        #video-container { position: absolute; bottom: 30px; right: 30px; width: 280px; height: 210px; border: 1px solid var(--neon); overflow: hidden; background: #000; z-index: 15; }
        #video-feed { width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); filter: grayscale(1) brightness(0.6) contrast(1.3); }
        #face-canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; transform: scaleX(-1); z-index: 20; pointer-events: none; }

        /* Skenavimo linija virš video */
        #video-container::after { content: ""; position: absolute; top: 0; left: 0; width: 100%; height: 2px; background: var(--neon); box-shadow: 0 0 15px var(--neon); animation: scan 3s linear infinite; }
        @keyframes scan { 0% { top: 0; } 100% { top: 100%; } }

        #ai-comms { position: absolute; bottom: 130px; left: 50%; transform: translateX(-50%); width: 80%; text-align: center; font-family: 'Space Mono'; font-size: 0.9rem; text-shadow: 0 0 10px var(--neon); color: #fff; text-transform: uppercase; letter-spacing: 1px; }
        .label { font-size: 0.6rem; opacity: 0.6; margin-bottom: 5px; letter-spacing: 2px; }
        .value { font-size: 1.1rem; font-family: 'Space Mono'; color: #fff; margin-bottom: 10px; }
    </style>
</head>
<body>

<div id="hud">
    <div id="panel-l" class="panel">
        <div class="label">NEURAL STATE</div>
        <div id="emo-val" class="value">IDLE</div>
        <div class="label">BIOMETRIC PULSE</div>
        <div class="value"><span id="bpm-val">--</span> BPM</div>
    </div>
    <div id="panel-r" class="panel">
        <div class="label">NEURAL DRIFT</div>
        <div id="drift-val" class="value">READY</div>
        <div class="label">SCAN PROGRESS</div>
        <div id="prog-val" class="value">0%</div>
    </div>
</div>

<div id="ai-comms">> INITIALIZE NEURAL LINK TO START BIOMETRIC ANALYSIS</div>
<button id="scan-trigger" onclick="initSystem()">START SCAN</button>

<div id="video-container">
    <video id="video-feed" autoplay muted playsinline></video>
    <canvas id="face-canvas"></canvas>
</div>

<script>
    let scene, camera, renderer, auraSphere, rings = [];
    let systemActive = false;
    let analysisData = [];
    const ANALYSIS_THRESHOLD = 150; 
    const MODEL_URL = 'https://raw.githubusercontent.com/vladmandic/face-api/master/model/';

    const EMOTION_THEMES = {
        neutral:  { color: 0x00f2ff, speed: 0.005 },
        happy:    { color: 0x00ff88, speed: 0.015 },
        sad:      { color: 0x0066ff, speed: 0.002 },
        angry:    { color: 0xff3300, speed: 0.040 },
        surprised:{ color: 0xffdd00, speed: 0.020 }
    };

    function speak(text) {
        window.speechSynthesis.cancel();
        const utter = new SpeechSynthesisUtterance(text);
        const voices = window.speechSynthesis.getVoices();
        const softVoice = voices.find(v => v.name.includes('Female') || v.name.includes('Zira') || v.name.includes('Google UK English Female'));
        if (softVoice) utter.voice = softVoice;
        utter.pitch = 1.05; utter.rate = 0.85;
        window.speechSynthesis.speak(utter);
        document.getElementById('ai-comms').innerText = "> IA: " + text;
    }

    function init3D() {
        scene = new THREE.Scene();
        camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        // Aura sfera
        const geometry = new THREE.IcosahedronGeometry(2.5, 15);
        const material = new THREE.MeshStandardMaterial({ color: 0x00f2ff, wireframe: true, transparent: true, opacity: 0.5 });
        auraSphere = new THREE.Mesh(geometry, material);
        scene.add(auraSphere);

        // Orbitaliniai žiedai
        for (let i = 0; i < 3; i++) {
            const rGeo = new THREE.TorusGeometry(3.5 + i * 0.7, 0.01, 16, 100);
            const rMat = new THREE.MeshBasicMaterial({ color: 0x7d2ae8, transparent: true, opacity: 0.2 });
            const ring = new THREE.Mesh(rGeo, rMat);
            rings.push(ring);
            scene.add(ring);
        }

        const light = new THREE.PointLight(0xffffff, 2, 100);
        light.position.set(5, 5, 5);
        scene.add(light);
        scene.add(new THREE.AmbientLight(0x404040, 2));
        camera.position.z = 10;

        function animate() {
            requestAnimationFrame(animate);
            if(auraSphere) {
                auraSphere.rotation.y += 0.002;
                rings.forEach((r, i) => { r.rotation.z += 0.001 * (i + 1); r.rotation.x += 0.0005; });
            }
            renderer.render(scene, camera);
        }
        animate();
    }

    function updateAuraVisuals(emotion, intensity) {
        if (!auraSphere) return;
        const theme = EMOTION_THEMES[emotion] || EMOTION_THEMES.neutral;
        
        // Spalvos ir mastelio lerp'as (švelnus perėjimas)
        auraSphere.material.color.lerp(new THREE.Color(theme.color), 0.05);
        const scale = 1 + (intensity * 0.4);
        auraSphere.scale.lerp(new THREE.Vector3(scale, scale, scale), 0.1);

        // Drift/Drebėjimas jei stresas aukštas
        if (emotion === 'angry' || emotion === 'sad') {
            auraSphere.position.x = (Math.random() - 0.5) * intensity * 0.2;
        } else {
            auraSphere.position.x *= 0.9;
        }
    }

    function drawNeurolink(landmarks) {
        const canvas = document.getElementById('face-canvas');
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        const pts = landmarks.positions;
        
        ctx.strokeStyle = 'rgba(0, 242, 255, 0.3)';
        ctx.lineWidth = 0.5;
        ctx.beginPath();
        for (let i = 0; i < pts.length; i++) {
            for (let j = i + 1; j < pts.length; j++) {
                const dist = Math.hypot(pts[i].x - pts[j].x, pts[i].y - pts[j].y);
                if (dist < 28) { // Tankesnis tinklas
                    ctx.moveTo(pts[i].x, pts[i].y);
                    ctx.lineTo(pts[j].x, pts[j].y);
                }
            }
        }
        ctx.stroke();
    }

    async function initSystem() {
        const btn = document.getElementById('scan-trigger');
        btn.disabled = true;
        document.getElementById('ai-comms').innerText = "> ACCESSING SENSORS...";

        try {
            await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
            await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
            await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);

            const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
            const video = document.getElementById('video-feed');
            video.srcObject = stream;

            video.onloadedmetadata = () => {
                const canvas = document.getElementById('face-canvas');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                systemActive = true;
                runLoop();
                speak("Neural link established. Scanning micro-expressions.");
            };
        } catch (e) {
            document.getElementById('ai-comms').innerText = "> ERROR: INITIALIZATION FAILED.";
            btn.disabled = false;
        }
    }

    function runLoop() {
        const video = document.getElementById('video-feed');
        setInterval(async () => {
            if (!systemActive) return;
            const res = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 512 })) // Aukšta raiška
                .withFaceLandmarks().withFaceExpressions();

            if (res) {
                drawNeurolink(res.landmarks);
                const top = Object.keys(res.expressions).reduce((a, b) => res.expressions[a] > res.expressions[b] ? a : b);
                const intensity = res.expressions[top];

                // Atnaujiname HUD
                document.getElementById('emo-val').innerText = top.toUpperCase();
                const bpm = Math.round(65 + (res.expressions.angry + res.expressions.happy) * 35);
                document.getElementById('bpm-val').innerText = bpm;
                
                analysisData.push(top);
                const prog = Math.min(100, Math.round((analysisData.length / ANALYSIS_THRESHOLD) * 100));
                document.getElementById('prog-val').innerText = prog + "%";
                document.getElementById('drift-val').innerText = (intensity > 0.8) ? "HIGH INTENSITY" : "STABLE";

                // Atnaujiname 3D aurą
                updateAuraVisuals(top, intensity);

                if (analysisData.length >= ANALYSIS_THRESHOLD) {
                    performReport();
                    analysisData = [];
                }
            }
        }, 80); // Greitesnis ciklas jautrumui
    }

    function performReport() {
        const counts = {};
        analysisData.forEach(e => counts[e] = (counts[e] || 0) + 1);
        const dominant = Object.keys(counts).reduce((a, b) => counts[a] > counts[b] ? a : b);
        
        const reports = {
            happy: "Your neural resonance is exceptionally high. Emotional harmony detected.",
            neutral: "Biometric stability confirmed. Your core signature is in equilibrium.",
            sad: "Lower frequency detected. Initiating mood recalibration protocols.",
            angry: "Neural friction identified. Recommending deep breath stabilization.",
            surprised: "Heightened cognitive alertness. Neural pathways are expanding."
        };
        speak(reports[dominant] || "Scan complete. Data synchronized.");
    }

    window.onload = () => { init3D(); window.speechSynthesis.getVoices(); };
</script>
</body>
</html>
