<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NEURO-CORE ELITE v2.0</title>
    <link href="https://fonts.googleapis.com/css2?family=Syncopate:wght@400;700&family=Space+Mono&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <style>
        :root { --neon: #00f2ff; --bg: #00050a; }
        body, html { margin: 0; padding: 0; background: var(--bg); color: var(--neon); font-family: 'Syncopate', sans-serif; overflow: hidden; height: 100%; }
        
        #hud { position: absolute; inset: 0; z-index: 10; padding: 30px; pointer-events: none; }
        .panel { position: absolute; background: rgba(0, 8, 15, 0.8); backdrop-filter: blur(15px); border: 1px solid rgba(0, 242, 255, 0.2); padding: 20px; pointer-events: auto; }
        #panel-l { top: 30px; left: 30px; border-left: 4px solid var(--neon); width: 250px; }
        #panel-r { top: 30px; right: 30px; border-right: 4px solid var(--neon); text-align: right; }
        
        #scan-trigger { position: absolute; bottom: 50px; left: 50%; transform: translateX(-50%); background: none; border: 2px solid var(--neon); color: var(--neon); padding: 15px 40px; font-family: 'Syncopate'; cursor: pointer; letter-spacing: 5px; z-index: 20; pointer-events: auto; transition: 0.3s; }
        #scan-trigger:hover { background: var(--neon); color: #000; box-shadow: 0 0 30px var(--neon); }
        #scan-trigger:disabled { opacity: 0.3; cursor: wait; }

        #video-container { position: absolute; bottom: 30px; right: 30px; width: 280px; height: 210px; border: 1px solid var(--neon); overflow: hidden; background: #000; }
        #video-feed { width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); filter: grayscale(1) brightness(0.7) contrast(1.2); }
        #face-canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; transform: scaleX(-1); z-index: 5; }

        #ai-comms { position: absolute; bottom: 130px; left: 50%; transform: translateX(-50%); width: 80%; text-align: center; font-family: 'Space Mono'; font-size: 0.9rem; text-shadow: 0 0 10px var(--neon); color: #fff; text-transform: uppercase; letter-spacing: 1px; }
        .label { font-size: 0.6rem; opacity: 0.6; margin-bottom: 5px; letter-spacing: 2px; }
        .value { font-size: 1.1rem; font-family: 'Space Mono'; color: #fff; }
    </style>
</head>
<body>

<div id="hud">
    <div id="panel-l" class="panel">
        <div class="label">NEURAL STATE</div>
        <div id="emo-val" class="value">STABLE</div>
    </div>
    <div id="panel-r" class="panel">
        <div class="label">SYSTEM STATUS</div>
        <div id="drift-val" class="value">READY</div>
    </div>
</div>

<div id="ai-comms">> INITIALIZE NEURAL LINK TO START BIOMETRIC ANALYSIS</div>
<button id="scan-trigger" onclick="initSystem()">START SCAN</button>

<div id="video-container">
    <video id="video-feed" autoplay muted playsinline></video>
    <canvas id="face-canvas"></canvas>
</div>

<script>
    let scene, camera, renderer, core;
    let systemActive = false;
    let analysisData = [];
    const ANALYSIS_THRESHOLD = 100; // ~10 sekundžių stebėjimo ciklas
    const MODEL_URL = 'https://raw.githubusercontent.com/vladmandic/face-api/master/model/';

    // --- 1. ŠVELNUS BALSAS ---
    function speak(text) {
        window.speechSynthesis.cancel();
        const utter = new SpeechSynthesisUtterance(text);
        const voices = window.speechSynthesis.getVoices();
        const softVoice = voices.find(v => v.name.includes('Female') || v.name.includes('Google UK English Female') || v.name.includes('Zira'));
        
        if (softVoice) utter.voice = softVoice;
        utter.lang = 'en-US';
        utter.pitch = 1.05;
        utter.rate = 0.9;
        window.speechSynthesis.speak(utter);
        document.getElementById('ai-comms').innerText = "> IA: " + text;
    }

    // --- 2. 3D BRANDUOLYS ---
    function init3D() {
        scene = new THREE.Scene();
        camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        const light = new THREE.PointLight(0x00f2ff, 10, 50);
        light.position.set(5, 5, 5);
        scene.add(light);
        scene.add(new THREE.AmbientLight(0x404040, 2));

        core = new THREE.Mesh(
            new THREE.IcosahedronGeometry(2.2, 15),
            new THREE.MeshStandardMaterial({ color: 0x00f2ff, wireframe: true, transparent: true, opacity: 0.6 })
        );
        scene.add(core);
        camera.position.z = 7;

        function animate() {
            requestAnimationFrame(animate);
            core.rotation.y += 0.003;
            core.rotation.x += 0.002;
            renderer.render(scene, camera);
        }
        animate();
    }

    // --- 3. GEOMETRINIS NEUROLINK TINKLAS ---
    function drawNeurolink(landmarks) {
        const canvas = document.getElementById('face-canvas');
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        const pts = landmarks.positions;
        ctx.strokeStyle = 'rgba(0, 242, 255, 0.4)';
        ctx.lineWidth = 0.5;

        // Piešiame linijas tarp taškų (geometrinis tinklas)
        ctx.beginPath();
        for (let i = 0; i < pts.length; i++) {
            for (let j = i + 1; j < pts.length; j++) {
                const dist = Math.hypot(pts[i].x - pts[j].x, pts[i].y - pts[j].y);
                if (dist < 25) { // Jungti tik artimus taškus
                    ctx.moveTo(pts[i].x, pts[i].y);
                    ctx.lineTo(pts[j].x, pts[j].y);
                }
            }
        }
        ctx.stroke();

        // Piešiame pačius mazgus
        ctx.fillStyle = '#00f2ff';
        pts.forEach(p => {
            ctx.beginPath();
            ctx.arc(p.x, p.y, 1, 0, Math.PI * 2);
            ctx.fill();
        });
    }

    // --- 4. PAGRINDINĖ ANALIZĖ ---
    async function initSystem() {
        const btn = document.getElementById('scan-trigger');
        const comms = document.getElementById('ai-comms');
        btn.disabled = true;
        comms.innerText = "> LOADING BIOMETRIC MODELS...";

        try {
            await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
            await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
            await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);

            const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
            const video = document.getElementById('video-feed');
            video.srcObject = stream;

            video.onloadedmetadata = () => {
                const canvas = document.getElementById('face-canvas');
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                systemActive = true;
                runLoop();
            };
        } catch (e) {
            comms.innerText = "> ERROR: INITIALIZATION FAILED.";
            btn.disabled = false;
        }
    }

    function runLoop() {
        const video = document.getElementById('video-feed');
        const canvas = document.getElementById('face-canvas');

        setInterval(async () => {
            if (!systemActive) return;

            const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions({ inputSize: 224 }))
                .withFaceLandmarks()
                .withFaceExpressions();

            if (detection) {
                drawNeurolink(detection.landmarks);
                
                const topEmotion = Object.keys(detection.expressions).reduce((a, b) => 
                    detection.expressions[a] > detection.expressions[b] ? a : b
                );

                document.getElementById('emo-val').innerText = topEmotion.toUpperCase();
                
                // Kaupiame duomenis
                analysisData.push(topEmotion);
                const progress = Math.min(100, Math.round((analysisData.length / ANALYSIS_THRESHOLD) * 100));
                document.getElementById('drift-val').innerText = `SCANNING ${progress}%`;

                if (analysisData.length >= ANALYSIS_THRESHOLD) {
                    performReport();
                }
            }
        }, 100);
    }

    function performReport() {
        const counts = {};
        analysisData.forEach(e => counts[e] = (counts[e] || 0) + 1);
        const dominant = Object.keys(counts).reduce((a, b) => counts[a] > counts[b] ? a : b);

        const reports = {
            happy: "Neural resonance is high. Your cognitive state is exceptionally positive.",
            neutral: "Core stability confirmed. Your neural signature is in perfect balance.",
            sad: "Minor frequency drop detected. Recalibrating emotional core. Please remain calm.",
            angry: "Neural friction identified. Suggesting immediate deep breathing exercises.",
            surprised: "Sudden spike in cognitive alertness. Neural field is expanding rapidly."
        };

        speak(reports[dominant] || "Analysis complete. Your energy is unique.");
        analysisData = []; // Resetinam kitam ciklui
    }

    window.onload = () => {
        init3D();
        // Užkrauname balsus iš anksto
        window.speechSynthesis.getVoices();
    };
</script>
</body>
</html>
